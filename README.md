# SEO Web Crawler

A comprehensive SEO web crawler and audit tool built with Next.js, designed to analyze websites, discover backlinks, and provide detailed SEO insights.

## Features

- ğŸ” **Website Crawling**: Automated crawling of websites with robots.txt and sitemap support
- ğŸ“Š **SEO Audits**: Comprehensive SEO analysis with technical, content, and performance scores
- ğŸ”— **Backlink Discovery**: Automatic discovery and tracking of backlinks
- ğŸ“ˆ **Dashboard**: Real-time monitoring of crawl progress and results
- ğŸ” **Authentication**: Magic Link authentication with email-based access control
- â¸ï¸ **Crawl Control**: Pause, resume, and stop crawling operations
- ğŸ“… **Scheduled Crawls**: Automated recurring crawls with configurable frequencies

## Tech Stack

- **Framework**: Next.js 16 (App Router)
- **Database**: PostgreSQL (Neon)
- **ORM**: Prisma
- **Queue**: Bull (Redis)
- **Authentication**: Magic Link
- **Styling**: Tailwind CSS

## Getting Started

### Prerequisites

- Node.js 18+ 
- PostgreSQL database (or Neon account)
- Redis instance
- Magic Link account (for authentication)

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd seo-web-crawler
```

2. Install dependencies:
```bash
npm install
```

3. Set up environment variables:
Create a `.env` file in the root directory:
```env
# Database
DATABASE_URL="your-postgresql-connection-string"

# Redis
REDIS_URL="your-redis-connection-string"

# Magic Link Authentication
NEXT_PUBLIC_MAGIC_PUBLISHABLE_KEY="your-magic-publishable-key"
MAGIC_SECRET_KEY="your-magic-secret-key"
```

4. Set up the database:
```bash
# Generate Prisma Client
npx prisma generate

# Run migrations
npx prisma migrate dev

# Initialize first user
npx tsx scripts/init-user.ts
```

5. Start the development server:
```bash
npm run dev
```

6. Start the queue worker (in a separate terminal):
```bash
npm run worker
```

Open [http://localhost:3000](http://localhost:3000) to access the application.

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/              # Next.js App Router pages
â”‚   â”‚   â”œâ”€â”€ api/          # API routes
â”‚   â”‚   â”œâ”€â”€ audits/       # Audit detail pages
â”‚   â”‚   â”œâ”€â”€ crawls/       # Crawl result pages
â”‚   â”‚   â”œâ”€â”€ projects/     # Project management pages
â”‚   â”‚   â”œâ”€â”€ users/        # User management page
â”‚   â”‚   â””â”€â”€ login/        # Authentication page
â”‚   â”œâ”€â”€ lib/              # Utility functions and libraries
â”‚   â”‚   â”œâ”€â”€ crawler.ts    # Main crawling logic
â”‚   â”‚   â”œâ”€â”€ queue.ts      # Queue management
â”‚   â”‚   â”œâ”€â”€ prisma.ts     # Database client
â”‚   â”‚   â””â”€â”€ auth-context.tsx # Authentication context
â”‚   â””â”€â”€ types/            # TypeScript type definitions
â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ schema.prisma    # Database schema
â””â”€â”€ scripts/
    â””â”€â”€ queue-worker.js   # Background queue worker
```

## Usage

### Creating a Project

1. Navigate to the dashboard
2. Enter a project name and base URL
3. Click "Start Crawl" to begin the initial crawl

### Managing Crawls

- **Pause**: Temporarily pause a running crawl (can be resumed)
- **Resume**: Continue a paused crawl
- **Stop**: Permanently stop a crawl (cannot be resumed)

### Viewing Results

- Access detailed audit results from the dashboard
- View individual crawl results and SEO scores
- Analyze backlinks and discover linking opportunities

## Authentication

The application uses Magic Link for passwordless authentication. Only users with emails registered in the database can log in.

To add a new user:
1. Use the `/users` page (requires admin access)
2. Or use the API endpoint: `POST /api/users`

## Database Schema

Key models:
- **User**: System users with email authentication
- **Project**: Websites being crawled
- **Audit**: Crawl sessions and their results
- **CrawlResult**: Individual page crawl data
- **Backlink**: Discovered backlinks
- **Issue**: SEO issues and recommendations

## API Endpoints

### Authentication
- `POST /api/auth/check-email` - Check if email exists
- `POST /api/auth/login` - Login with Magic Link
- `POST /api/auth/logout` - Logout
- `GET /api/auth/me` - Get current user

### Projects
- `GET /api/projects` - List all projects
- `POST /api/projects` - Create new project
- `GET /api/projects/[id]` - Get project details

### Audits
- `GET /api/audits/[auditId]` - Get audit details
- `POST /api/audits/[auditId]/start-auto` - Start automatic crawl
- `POST /api/audits/[auditId]/pause` - Pause crawl
- `POST /api/audits/[auditId]/resume` - Resume crawl
- `POST /api/audits/[auditId]/stop` - Stop crawl

### Users
- `GET /api/users` - List all users
- `POST /api/users` - Create new user

## Development

### Running Tests
```bash
npm run lint
```

### Database Migrations
```bash
# Create a new migration
npx prisma migrate dev --name migration-name

# Apply migrations in production
npx prisma migrate deploy
```

### Queue Management
```bash
# Clear the queue
POST /api/queue/clear

# Check queue status
GET /api/queue/status
```

## Deployment

See [VERCEL_DEPLOYMENT.md](./VERCEL_DEPLOYMENT.md) for deployment instructions.

## License

Private project - All rights reserved
